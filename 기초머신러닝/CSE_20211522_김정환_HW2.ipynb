{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrBgIzwPxgwO","outputId":"fef1388d-848b-49fe-9b16-7d230ee10848","executionInfo":{"status":"ok","timestamp":1748616245031,"user_tz":-540,"elapsed":3191,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import os\n","import glob\n","import cv2\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YEAGtTXXveZ3","executionInfo":{"status":"ok","timestamp":1748615178282,"user_tz":-540,"elapsed":13,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def load_dataset(data_dir):\n","    \"\"\"\n","    Load all grayscale .jpg images from a directory and flatten them into column vectors.\n","\n","    Args:\n","        data_dir (str): Path to the folder containing .jpg images.\n","\n","    Returns:\n","        X (np.ndarray): 2D array of shape (D, N), where D = H * W (flattened image size)\n","                        and N = number of images.\n","        labels (List[int]): List of length N with integer labels parsed from the\n","                            first two characters of each filename.\n","    \"\"\"\n","    # Find and sort all .jpg files in the directory\n","    paths = sorted(glob.glob(os.path.join(data_dir, '*.jpg')))\n","    data, labels = [], []\n","\n","    for p in paths:\n","        # Read image as grayscale\n","        img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n","        if img is None:\n","            # Skip files that cannot be read\n","            continue\n","\n","        # Transpose so that flattening matches D = H*W ordering,\n","        # then convert to float32 and flatten to a vector\n","        vec = img.T.flatten().astype(np.float32)\n","        data.append(vec)\n","\n","        # Extract label from first two characters of the filename\n","        labels.append(int(os.path.basename(p)[:2]))\n","\n","    # Stack all vectors into a (D, N) array\n","    X = np.stack(data, axis=1)\n","    return X, labels\n","\n","def compute_pairwise_distances(X, Y, metric='l2'):\n","    \"\"\"\n","    Compute pairwise distances between two sets of vectors using the specified metric.\n","\n","    Args:\n","        X (np.ndarray): Array of shape (D, M), representing M query vectors of dimensionality D.\n","        Y (np.ndarray): Array of shape (D, N), representing N reference vectors of dimensionality D.\n","        metric (str): Distance metric to use; either 'l2' for Euclidean distance or 'l1' for Manhattan distance.\n","\n","    Returns:\n","        np.ndarray: Distance matrix of shape (M, N), where entry (i, j) is the distance between X[:, i] and Y[:, j].\n","\n","    Raises:\n","        ValueError: If an unsupported metric string is provided.\n","    \"\"\"\n","    if metric == 'l2':\n","        # Use Euclidean (L2) distance\n","        return calc_l2(X, Y)\n","    elif metric == 'l1':\n","        # Use Manhattan (L1) distance\n","        return calc_l1(X, Y)\n","    else:\n","        # Reject unknown metrics\n","        raise ValueError(f\"Unknown metric: {metric}\")\n","\n","def calc_l2(X, Y):\n","    \"\"\"\n","    Compute pairwise L2 (Euclidean) distances between two sets of vectors.\n","\n","    Args:\n","        X (np.ndarray): Array of shape (D, M), M query vectors.\n","        Y (np.ndarray): Array of shape (D, N), N reference vectors.\n","\n","    Returns:\n","        np.ndarray: Matrix of shape (M, N) where entry (i, j) is\n","                    ||X[:, i] - Y[:, j]||_2.\n","    \"\"\"\n","    # Expand dims to broadcast subtraction: result shape (D, M, N)\n","    diff = X[:, :, None] - Y[:, None, :]\n","    # Sum squared differences over D, then take square root\n","    return np.sqrt((diff ** 2).sum(axis=0))\n","\n","\n","def calc_l1(X, Y):\n","    \"\"\"\n","    Compute pairwise L1 (Manhattan) distances between two sets of vectors.\n","\n","    Args:\n","        X (np.ndarray): Array of shape (D, M), M query vectors.\n","        Y (np.ndarray): Array of shape (D, N), N reference vectors.\n","\n","    Returns:\n","        np.ndarray: Matrix of shape (M, N) where entry (i, j) is\n","                    ||X[:, i] - Y[:, j]||_1.\n","    \"\"\"\n","    # Expand dims and sum absolute differences over D\n","    return np.abs(X[:, :, None] - Y[:, None, :]).sum(axis=0)\n","\n","def match_accuracy(X_train, y_train, X_test, y_test, metric='l2'):\n","    \"\"\"\n","    Perform nearest-neighbor classification and compute accuracy.\n","\n","    For each test vector, find the closest training vector using the specified\n","    distance metric, then compare its label to the true test label.\n","\n","    Args:\n","        X_train (np.ndarray): Training data of shape (D, N_train).\n","        y_train (List[int]): Labels for training data, length N_train.\n","        X_test (np.ndarray): Test data of shape (D, N_test).\n","        y_test (List[int]): True labels for test data, length N_test.\n","        metric (str): Distance metric to use; either 'l1' or 'l2'.\n","\n","    Returns:\n","        float: Classification accuracy (between 0 and 1).\n","    \"\"\"\n","    # Choose the appropriate distance function\n","    if metric == 'l2':\n","        distances = calc_l2(X_test, X_train)\n","    elif metric == 'l1':\n","        distances = calc_l1(X_test, X_train)\n","    else:\n","        raise ValueError(\"metric must be 'l1' or 'l2'\")\n","\n","    # Predict the label of the nearest neighbor for each test sample\n","    preds = [y_train[np.argmin(dist_row)] for dist_row in distances]\n","\n","    # Compute mean accuracy\n","    return np.mean([pred == true for pred, true in zip(preds, y_test)])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"aZ6uHhzoDtNp","executionInfo":{"status":"ok","timestamp":1748616330766,"user_tz":-540,"elapsed":23,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def compute_centered_matrix(X_tr):\n","    \"\"\"\n","    Center the input data by subtracting its mean vector.\n","\n","    Args:\n","        X_tr (ndarray of shape (D, N)):\n","            Original data matrix, where D is the feature dimension\n","            and N is the number of samples.\n","\n","    Returns:\n","        X_centered (ndarray of shape (D, N)):\n","            Data matrix after subtracting the mean from each column.\n","        mu (ndarray of shape (D,)):\n","            Mean vector computed across all samples.\n","    \"\"\"\n","    # Compute the mean of each feature (row) over all samples (columns)\n","    # Subtract the mean from each column to center the data\n","    mu = np.mean(X_tr, axis=1)\n","    X_centered = X_tr - mu[:,None]\n","    return X_centered, mu"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"sf_m4JeSEKYE","executionInfo":{"status":"ok","timestamp":1748615582949,"user_tz":-540,"elapsed":13,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def compute_covariance_matrix(X_centered):\n","    \"\"\"\n","    Compute the covariance matrix of centered data.\n","\n","    Args:\n","        X_centered (ndarray of shape (D, N)):\n","            Centered data matrix.\n","\n","    Returns:\n","        C (ndarray of shape (D, D)):\n","            Covariance matrix, where C[i, j] is the covariance\n","            between feature i and feature j.\n","    \"\"\"\n","    # bias=True uses denominator N instead of N-1\n","    C = np.cov(X_centered, bias=True)\n","    return C"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YE0AiFq9EScS","executionInfo":{"status":"ok","timestamp":1748615686858,"user_tz":-540,"elapsed":48,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def eigen_decomposition(C):\n","    \"\"\"\n","    Perform standard eigen decomposition on a covariance matrix.\n","\n","    Args:\n","        C (ndarray of shape (D, D)):\n","            Covariance matrix.\n","\n","    Returns:\n","        eigvals (ndarray of length D):\n","            Eigenvalues sorted in descending order.\n","        eigvecs (ndarray of shape (D, D)):\n","            Corresponding eigenvectors as columns.\n","    \"\"\"\n","    # Compute all eigenvalues and eigenvectors\n","    # Sort in descending order\n","    eigvals, eigvecs = np.linalg.eigh(C)\n","    idx = np.argsort(eigvals)[::-1]\n","    eigvals = eigvals[idx]\n","    eigvecs = eigvecs[:, idx]\n","    return eigvals, eigvecs"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nmGf2PEjD7Zh","executionInfo":{"status":"ok","timestamp":1748615834071,"user_tz":-540,"elapsed":5,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def svd_eigen(X_centered):\n","    \"\"\"\n","    Extract singular values from the centered data via SVD.\n","\n","    Args:\n","        X_centered (ndarray of shape (D, N)):\n","            Centered data matrix.\n","\n","    Returns:\n","        S (ndarray of length min(D, N)):\n","            Singular values of X_centered.\n","    \"\"\"\n","    # U and Vt are discarded here; we only need S\n","    _, S, _ = np.linalg.svd(X_centered, full_matrices=False)\n","    return S\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"R9P5rDkID9Md","executionInfo":{"status":"ok","timestamp":1748615899082,"user_tz":-540,"elapsed":20,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def svd_eigen_decomposition(S, N):\n","    \"\"\"\n","    Convert singular values to covariance eigenvalues.\n","\n","    Args:\n","        S (array-like of length min(D, N)):\n","            Singular values from SVD.\n","        N (int):\n","            Number of samples (used to normalize).\n","\n","    Returns:\n","        eigvals_svd (ndarray of length min(D, N)):\n","            Eigenvalues of the covariance matrix computed as S**2 / N.\n","    \"\"\"\n","    eigvals_svd = (S ** 2) / N\n","    return eigvals_svd"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MqNNuVhAD-WD","executionInfo":{"status":"ok","timestamp":1748616031058,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def projection(X, basis, mu):\n","    \"\"\"\n","    Project data onto a lower-dimensional basis.\n","\n","    Args:\n","        X (ndarray of shape (D, N)):\n","            Original data matrix.\n","        basis (ndarray of shape (D, k)):\n","            Matrix whose columns are the top-k basis vectors.\n","        mu (ndarray of shape (D,)):\n","            Mean vector used for centering.\n","\n","    Returns:\n","        P (ndarray of shape (k, N)):\n","            Coordinates of each sample in the new basis.\n","    \"\"\"\n","    # Center X and then multiply by the basis vectors\n","    X_centered = X - mu[:, None]\n","    P = basis.T @ X_centered\n","    return P"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"751CktGDSrrW","executionInfo":{"status":"ok","timestamp":1748616164751,"user_tz":-540,"elapsed":7,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def select_components(eigvals, threshold):\n","    \"\"\"\n","    Determine how many principal components to keep to retain given energy.\n","\n","    Args:\n","        eigvals (array-like of length D):\n","            Eigenvalues sorted in descending order.\n","        threshold (float in (0, 1]):\n","            Fraction of total variance to retain.\n","\n","    Returns:\n","        k (int):\n","            Minimum number of leading components such that\n","            cumulative variance ≥ threshold.\n","    \"\"\"\n","    # searchsorted returns the first index where cum_ratio >= threshold\n","    cum_ratio = np.cumsum(eigvals) / np.sum(eigvals)\n","    k = np.searchsorted(cum_ratio, threshold) + 1\n","    return k"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BPn1IS4wxyxc","executionInfo":{"status":"ok","timestamp":1748616166666,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[],"source":["def proj2(data_root):\n","    # Load training and testing data\n","    X_tr, y_tr = load_dataset(os.path.join(data_root, 'train'))\n","    X_te, y_te = load_dataset(os.path.join(data_root, 'test'))\n","\n","    # Determine dimensions\n","    D, N = X_tr.shape\n","\n","    # Part 1: Covariance-based Eigen Decomposition\n","    print(\"=== Part 1: Covariance Eigen Decomposition ===\")\n","    X_centered, mu = compute_centered_matrix(X_tr)\n","    C = compute_covariance_matrix(X_centered)\n","    eigvals, eigvecs = eigen_decomposition(C)\n","    print(f\"Computed {D} eigenvalues from {D}×{D} covariance matrix.\")\n","    print(f\"Top-10 eigenvalues: {eigvals[:10]}\\n\")\n","\n","    # Part 2: SVD Eigen Decomposition\n","    print(\"=== Part 2: SVD Eigen Decomposition ===\")\n","    S = svd_eigen(X_centered)\n","    eigvals_svd = svd_eigen_decomposition(S, N)\n","    print(f\"Computed {len(S)} singular values from {D}×{N} centered data.\")\n","    print(f\"Top-10 SVD-based eigenvalues: {eigvals_svd[:10]}\")\n","\n","    # Optional similarity check using L1 / L2 distances\n","    padded_svd = np.concatenate([eigvals_svd, np.zeros(D - len(eigvals_svd))])\n","    X_vec = eigvals[:, None]  # shape (D, 1)\n","    Y_vec = padded_svd[:, None]  # shape (D, 1)\n","\n","    # compute L1 and L2 distances\n","    l1_dist = compute_pairwise_distances(X_vec, Y_vec, metric='l1')[0, 0]\n","    l2_dist = compute_pairwise_distances(X_vec, Y_vec, metric='l2')[0, 0]\n","    print(f\"Eigenvalue sequences L1 distance: {l1_dist:.6f}\")\n","    print(f\"Eigenvalue sequences L2 distance: {l2_dist:.6f}\\n\")\n","\n","\n","    # Part 3: Projection and Matching Accuracy\n","    print(\"=== Part 3: Projection & Matching Accuracy ===\")\n","    def match_on_basis(basis, label):\n","        P_tr = projection(X_tr, basis, mu)\n","        P_te = projection(X_te, basis, mu)\n","        acc = match_accuracy(P_tr, y_tr, P_te, y_te, 'l2')\n","        print(f\"{label}: L2 accuracy = {acc*100:.2f}%\")\n","\n","    match_on_basis(eigvecs, 'Full basis')\n","\n","    # Part 4: Energy Threshold Impact\n","    print(\"\\n=== Part 4: Energy Threshold Impact ===\")\n","    for thr in (0.90, 0.95):\n","        k = select_components(eigvals, thr)\n","        basis_k = eigvecs[:, :k]\n","        acc_k = match_accuracy(projection(X_tr, basis_k, mu), y_tr,\n","                               projection(X_te, basis_k, mu), y_te, 'l2')\n","        storage_drop = (1 - k/D) * 100\n","        print(f\"Energy {int(thr*100)}% (k={k}): accuracy={acc_k*100:.2f}%, storage↓{storage_drop:.1f}%\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqOuUD82yhGh","outputId":"84e82b52-a548-46a0-9028-0e20c1ff428c","executionInfo":{"status":"ok","timestamp":1748616403231,"user_tz":-540,"elapsed":21403,"user":{"displayName":"김정환","userId":"04892211398989016159"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Project 2 =====\n","=== Part 1: Covariance Eigen Decomposition ===\n","Computed 1764 eigenvalues from 1764×1764 covariance matrix.\n","Top-10 eigenvalues: [2738657.29557341  937279.85673454  331728.34354099  186819.89489465\n","  141655.12260084  114923.07160831  108920.02556153   85017.9533288\n","   67741.6417524    58794.04244069]\n","\n","=== Part 2: SVD Eigen Decomposition ===\n","Computed 350 singular values from 1764×350 centered data.\n","Top-10 SVD-based eigenvalues: [2738657.2   937279.8   331728.34  186819.89  141655.12  114923.08\n","  108920.02   85017.95   67741.65   58794.04]\n","Eigenvalue sequences L1 distance: 0.174070\n","Eigenvalue sequences L2 distance: 0.065031\n","\n","=== Part 3: Projection & Matching Accuracy ===\n","Full basis: L2 accuracy = 96.00%\n","\n","=== Part 4: Energy Threshold Impact ===\n","Energy 90% (k=37): accuracy=96.00%, storage↓97.9%\n","Energy 95% (k=81): accuracy=94.00%, storage↓95.4%\n"]}],"source":["data_root = '/content/drive/MyDrive/HW1/data/'  # folders: data/train, data/test, data/test2\n","print(\"\\n===== Project 2 =====\")\n","proj2(data_root)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cGtdPdnETvz"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}